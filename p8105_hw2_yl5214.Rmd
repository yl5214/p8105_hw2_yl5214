---
title: "p8105_hw2_yl5214"
author: "Yi Li"
output: github_document
---

```{r}
library(tidyverse)
library(readxl)
```

### Question 1
##Clean the data in pols_month.csv
```{r}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )
pols = 
  read_csv("data/fivethirtyeight_datasets/pols-month.csv") |>
  separate(mon, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
   left_join(x = _, y = month_df) |>
  select(year, month, everything(), -day, -starts_with("prez")) 
```

## Clean the data in snp.csv

```{r}
snp = 
  read_csv(
    "./data/fivethirtyeight_datasets/snp.csv",
    col_types = cols(date = col_date(format = "%m/%d/%y"))) |>
  separate(date, into = c("year", "month_num", "day"), convert = TRUE) |>
  mutate(
    year = if_else(year > 2023, year - 100, year)) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, close) 
```

##  Tidy the unemployment data
```{r}
unemployment = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") |>
  rename(year = Year) |>
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) |> 
  select(year, month, unemployment)
```

## Merge the three datasets

```{r}
merge = 
  left_join(pols, snp) |>
  left_join(x = _, y = unemployment)

str(merge)
```
There are `r nrow(merge)` observations  and `r ncol(merge)` variables in this merge dataset. The key variables are `r names(merge)`.



## Question 2
## Read and clean the Mr. Trash Wheel sheet
```{r}
Mr_trash_df =
  read_excel('data/202309 Trash Wheel Collection Data.xlsx', sheet = 1, range = "A2:N586") |> 
  janitor::clean_names() |> 
  mutate( trash_wheel= 'Mr_trash_wheel') |> 
  mutate( year= as.double(year)) |> 
  drop_na (dumpster) |> 
  mutate(
    homes_powered = weight_tons*500/30
    ) 
```


## Import, clean, and organize the data for Professor Trash Wheel and Gwynnda
```{r}
professor_trash_df =
  read_excel('data/202309 Trash Wheel Collection Data.xlsx', sheet = 2, range = "A2:M108") |> 
  janitor::clean_names() |>
  mutate( trash_wheel= 'professor_trash_wheel') |>
   mutate( year= as.double(year))|>
  drop_na (dumpster) |> 
  mutate(
    homes_powered = weight_tons*500/30
  )

gwynnda_df =
  readxl::read_excel('data/202309 Trash Wheel Collection Data.xlsx', sheet = 4, range = "A2:L157", na ="") |>
  janitor::clean_names() |>
  mutate( trash_wheel= 'gwynnda_trash_wheel') |>
  mutate( year= as.double(year))|>
 janitor::clean_names() |> 
  drop_na (dumpster) |> 
  mutate(
    homes_powered = weight_tons*500/30
  ) 

```

## Gwynnda in July of 2021
```{r}
total_cig =filter(gwynnda_df, year =='2021', month =='July')
```


## Combine these with the Mr. Trash Wheel dataset to produce a single tidy dataset
```{r}
combine_df =
  bind_rows(Mr_trash_df, professor_trash_df, gwynnda_df) |> 
  janitor::clean_names() |> 
relocate(trash_wheel)
```

## Description
There are `r nrow(combine_df)` observations  and `r ncol(combine_df)` variables and tells us about the different types of trash in what dumspter and trash wheel and the corresponding weight, volumn for a given date. This dataset also contains homes_powered, which estimates the number of homes that could be powered from the energy saved by the trash collection.The key variables are `r names(combine_df)`. The total weight of trash collected by Professor Trash Wheel is `r sum(pull(professor_trash_df(weight_tons))` The total number of cigarette butts collected by Gwynnda in July of 2021 is `r sum(pull (total_cig(cigarette_butts))`

## Question 3


## Import, clean, and tidy the dataset of baseline demographics
```{r}
mci_baseline=
  read_csv("data/MCI_baseline.csv", 
           skip= 1)|> 
  janitor:: clean_names() |> 
  filter ( current_age < age_at_onset| age_at_onset == "." ) |> 
    mutate(
       sex = case_match(
         sex,
        0 ~ "female",
        1 ~ "male"
        )
) |> 
       mutate(
        apoe4 =case_match(
          apoe4,
        0 ~ " APOE4 non-carrier",
        1 ~ "APOE4 carrier" 
        ) 
) 


```

##Discuss important steps in the import process and relevant features of the dataset.
First, I delete a row at the top of the dataset because the first row does not contain the variable names for each column. Then, I remove the participants who do not meet the stated inclusion criteria by filtering current age less than the age at onset or the age at onset is ".". Then, I change the sex status from 1, 0 to male, female by using the mutate statement. Also, I change the apoe4 carrier status from 1, 0 to APOE4 carrier, APOE4 non-carrier by using mutate statement. There are `r nrow(mci_baseline)` observations in the merged dataset. The key variables are `r names(mci_baseline)`.

##How many participants were recruited, and of these how many develop MCI?
Those who develop MCI
```{r}
baseline2= filter(mci_baseline, age_at_onset != '.')
```
`r nrow(mci_baseline)` participants were recruited, and of these `r nrow(baseline2)` develop MCI.
##What is the average baseline age? 
The average baseline age is `r mean(mci_baseline$current_age)` 
## What proportion of women in the study are APOE4 carriers?
```{r}
proportion=
  sum(mci_baseline$sex == "female" & mci_baseline$ apoe4 == "APOE4 carrier") / sum(mci_baseline$sex == "female")
```
`r proportion` women in the study are APOE4 carriers.

##Import, clean, and tidy the dataset of longitudinally observed biomarker values
```{r}
mci_amyloid=
  read_csv("data/mci_amyloid.csv", 
           skip= 1)|> 
  janitor:: clean_names() |> 
  rename(id = study_id) |> 
  pivot_longer(
   baseline: time_8,
   names_to ='time',
   values_to = 'amyloid_value',
   names_prefix ='time_'
   )|>
     mutate(
       time = replace(time, time== 'baseline', '0')
     )

```

## amyloid data without pivot_longer
```{r}
mci_amyloid1=
  read_csv("data/mci_amyloid.csv", 
           skip= 1)|> 
  janitor:: clean_names() |> 
  rename(id = study_id)
```

## Comment on the steps on the import process and the features of the dataset
First, I delete a row at the top of the dataset because the first row does not contain the variable names for each column. Then, I rename study_id by id because I want to keep this unique id same to the baseline dataset. Then, I use pivote_longer statement to melt data frames from a wide format into a long format. Also, I delete the prefix of time_ and change the 'baseline' to 0 to make the dataset tidier and cleaner. There are `r nrow(mci_amyloid)` observations and `r ncol(mci_amyloid)` variables and tells us about the amyloid value in each visit time for each specific patient.

## Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained
```{r}
mci_merge =
  inner_join(mci_amyloid1, mci_baseline, by = 'id')
```

##Describe the resulting dataset
There are `r nrow(mci_merge)` observations and `r ncol(mci_merge)` variables and tells us not only about the patient information, but also the amyloid value for everytime the patient follows up. The key variables are `r names(mci_merge)`.

## Combine the demographic and biomarker datasets ï¼Œall the participants are retained
```{r}
mci_combine=
  full_join(mci_amyloid1, mci_baseline, by ='id')
```
## Check whether some participants appear in only the baseline or amyloid datasets
`r nrow(mci_combine)-nrow(mci_baseline) ` participants appears in only the amyloid dataset and not in baseline dataset.

`r nrow(mci_combine)-nrow(mci_amyloid1) ` participants appears in only the baseline dataset and not in amyloid dataset.

## Export the result as a CSV to your data directory
write.csv(mci_merge, "data/mci_merge.csv")




